{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For ploting the results of the gan training\n",
    "So first run signal_GAN_train.py and then signal_GAN_test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# my perfered plotting settings\n",
    "pal = sns.color_palette(\"colorblind\")\n",
    "plt.style.use('plot_style.txt')\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "from NuRadioReco.utilities import units, fft\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = pd.read_pickle(f'GAN_losses/signal_gan_results_transconv-incept-m14-10deg-05split-fixed.pkl')\n",
    "energy_err = models['energy_err']\n",
    "index_best = np.argmin(energy_err)\n",
    "print('best model:', models.iloc[index_best]['name'])\n",
    "# note that the best model has changed slightly since the results for the report since \n",
    "# I re-ran the test of them and I guess the generated signals were different that time.\n",
    "# only a 1% difference though"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and normalize the data\n",
    "The normalization changes depending on the range of angles used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('/mnt/md0/aholmberg/data/signal_had_14_10deg.npy')\n",
    "condition = data[:,:2]\n",
    "shower_n = data[:,3]\n",
    "signals = data[:,3:]\n",
    "signals_filtered = np.load('/mnt/md0/aholmberg/data/signal_had_14_filtered_10deg.npy')\n",
    "\n",
    "latent_dim = 112\n",
    "N = 896\n",
    "n_index = 1.78\n",
    "cherenkov_angle = np.arccos(1. / n_index)\n",
    "\n",
    "condition_norm = condition.copy()  # normalize to get range (0,1)\n",
    "condition_norm[:, 0] = (np.log10(condition_norm[:, 0]) - 15)/(19 - 15)\n",
    "#condition_norm[:, 1] = ((condition_norm[:, 1] - cherenkov_angle) / units.deg + 2.5)/ 5\n",
    "condition_norm[:, 1] = ((condition_norm[:, 1] - cherenkov_angle) / units.deg + 5)/ 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a model from a random grid search from train_signal_GAN.py\n",
    "Specify the name and directory of the saved models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'run4-lr=5e-05-critic_filters=24-generator_filters=48-generator_k_size=15' \n",
    "g_model = keras.models.load_model(f'/mnt/md0/aholmberg/GAN_models/transconv-incept-m14-10deg-05split-fixed/gen_{name}/', compile=False)\n",
    "g_model.compile()\n",
    "\n",
    "test_split = 0.5\n",
    "ind = int(signals_filtered.shape[0]*test_split)\n",
    "\n",
    "test_signals = signals_filtered[ind:, :]\n",
    "test_conditions = condition[ind:, :]\n",
    "test_conditions_norm = condition_norm[ind:, :]\n",
    "\n",
    "# idepends on the test split. Makes sure that thera are ten signals of the same conditions\n",
    "i = 0\n",
    "\n",
    "test_signal = test_signals[i:i+10, :]\n",
    "test_condition = test_conditions[i:i+10, :]\n",
    "test_condition_norm = test_conditions_norm[i:i+10, :]\n",
    "\n",
    "latent_vec = tf.random.normal((10, latent_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict ten signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_signals = g_model([latent_vec, test_condition_norm], training=False)\n",
    "pred_signals.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale those ten signals depending on the scaling used when traning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred_signals_scaled = pred_signals / (np.expand_dims(1e19/test_condition[:, 0], axis=-1) * (np.expand_dims(((test_condition[:, 1]/units.deg - cherenkov_angle/units.deg))**4, axis=-1) + 1)/3)\n",
    "pred_signals_scaled = pred_signals / (np.expand_dims(1e19/test_condition[:, 0], axis=-1) * (np.expand_dims(((test_condition[:, 1]/units.deg - cherenkov_angle/units.deg))**4, axis=-1) + 1)/6)\n",
    "\"\"\" pred_signals_scaled = np.zeros_like(pred_signals)\n",
    "for i in range(pred_signals.shape[0]):\n",
    "    pred_signals_scaled[i,:] = pred_signals[i,:]/(1e19/test_condition[i, 0])\n",
    " \"\"\"\n",
    "print(f'E: {test_condition[:,0]},\\n theta: {test_condition[:,1]/units.deg},\\n norm: {test_condition_norm}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot a signal and a generated signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0,89.6, 896)\n",
    "plt.plot(x[100:770], pred_signals_scaled[1,100:770], label='generated signal')\n",
    "plt.plot(x[100:770], test_signal[1,100:770], '--', label='true signal')\n",
    "plt.legend()\n",
    "plt.xlabel('time [ns]')\n",
    "plt.ylabel('amplitude [V/m]')\n",
    "#plt.savefig('gensig.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourier transform the real and predicted signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 1e-10 * units.second\n",
    "sr = 1/dt\n",
    "ff = np.fft.rfftfreq(N, dt)\n",
    "\n",
    "pred_spectrum = np.zeros((10, 449))\n",
    "real_spectrum = np.zeros((10, 449))\n",
    "for index in range(10):\n",
    "    pred_spectrum[index, :] = np.abs(fft.time2freq(pred_signals_scaled[index, :], sampling_rate=sr))\n",
    "    real_spectrum[index, :] = np.abs(fft.time2freq(test_signal[index, :], sampling_rate=sr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the mean and bounds of generated signals snd their spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pred = np.mean(pred_signals_scaled, axis=0)\n",
    "max_pred = np.max(pred_signals_scaled, axis=0)\n",
    "min_pred = np.min(pred_signals_scaled, axis=0)\n",
    "mean_real = np.mean(test_signal, axis=0)\n",
    "max_real = np.max(test_signal, axis=0)\n",
    "min_real = np.min(test_signal, axis=0)\n",
    "\n",
    "mean_pred_spectrum = np.mean(pred_spectrum, axis=0)\n",
    "max_pred_spectrum = np.max(pred_spectrum, axis=0)\n",
    "min_pred_spectrum = np.min(pred_spectrum, axis=0)\n",
    "mean_real_spectrum = np.mean(real_spectrum, axis=0)\n",
    "max_real_spectrum = np.max(real_spectrum, axis=0)\n",
    "min_real_spectrum = np.min(real_spectrum, axis=0)\n",
    "\n",
    "fig, ax = plt.subplots(2,2, figsize=(10,10), sharey='row')\n",
    "ax[0, 0].plot(x[100:770], mean_pred[100:770], 'r', label=f'mean of generated signals')\n",
    "ax[0, 0].plot(x[100:770], mean_real[100:770], '--b',label=f'mean of true signals')\n",
    "\n",
    "ax[0, 1].fill_between(x[100:770], min_pred[100:770], max_pred[100:770], label=f'min/max bounds for generated signals', color='r')\n",
    "ax[0, 1].fill_between(x[100:770], min_real[100:770], max_real[100:770], label=f'min/max bounds for real signals', color='b')\n",
    "\n",
    "ax[1, 0].plot(ff, mean_pred_spectrum, 'r', label='mean spectrum of generated signals')\n",
    "ax[1, 0].plot(ff, mean_real_spectrum, 'b', label='mean spectrum of real signals')\n",
    "\n",
    "ax[1, 1].fill_between(ff, min_pred_spectrum, max_pred_spectrum, label=f'min/max bounds of the spectrum for generated signals', color='r')\n",
    "ax[1, 1].fill_between(ff, min_real_spectrum, max_real_spectrum, label=f'min/max bounds of the spectrum for real signals', color='b')\n",
    "\n",
    "ax[0, 0].legend(loc=1)\n",
    "ax[0, 1].legend(loc=1)\n",
    "ax[1, 0].legend(loc=1)\n",
    "ax[1, 1].legend(loc=1)\n",
    "ax[0, 0].set_xlabel('time [ns]')\n",
    "ax[0, 1].set_xlabel('time [ns]')\n",
    "ax[0, 0].set_ylabel('amplitude [V/m]')\n",
    "ax[1, 0].set_xlabel('frequency [GHz]')\n",
    "ax[1, 0].set_ylabel('amplitude [V/m/GHz]')\n",
    "ax[1, 1].set_xlabel('frequency [GHz]')\n",
    "theta = r'$\\theta$'\n",
    "deg = r'$^\\circ$'\n",
    "fig.suptitle(f'Signal and spectrum for 10 generated signals and 10 real signals \\n with different shower profiles, E={test_condition[0,0]:.2e} [eV] {theta}={test_condition[0, 1]/ units.deg :.2f} [{deg}]')\n",
    "#fig.savefig('plots/40deg_gen_sig_E181e17_theta6839.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now predict all of the test signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "test_signals = signals_filtered[ind+(i%10):, :]\n",
    "test_conditions = condition[ind+(i%10):, :]\n",
    "test_conditions_norm = condition_norm[ind+(i%10):, :]\n",
    "latent_vec = tf.random.normal((test_conditions.shape[0], latent_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_signals = g_model.predict([latent_vec, test_conditions_norm])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale those test signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred_signals_scaled = pred_signals.copy() / (np.expand_dims(1e19/test_conditions[:, 0], axis=-1) * (np.expand_dims(((test_conditions[:, 1]/units.deg - cherenkov_angle/units.deg))**4, axis=-1) + 1)/3)\n",
    "pred_signals_scaled = pred_signals.copy() / (np.expand_dims(1e19/test_conditions[:, 0], axis=-1) * (np.expand_dims(((test_conditions[:, 1]/units.deg - cherenkov_angle/units.deg))**4, axis=-1) + 1)/6)\n",
    "\"\"\" pred_signals_scaled = np.zeros_like(pred_signals)\n",
    "for i in range(pred_signals.shape[0]):\n",
    "    pred_signals_scaled[i,:] = pred_signals[i,:]/(1e19/test_conditions[i, 0]) \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the critic and compile it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c_model = keras.models.load_model(f'/mnt/md0/aholmberg/GAN_models/transconv-incept_1/crit_{name}/', compile=False)\n",
    "#c_model = keras.models.load_model(f'/mnt/md0/aholmberg/GAN_models/transconv-incept_1/crit_run0_lr=1e-05_critic_filters=8_generator_filters=32_generator_k_size=5/', compile=False)\n",
    "c_model = keras.models.load_model(f'/mnt/md0/aholmberg/GAN_models/transconv-incept-m14-10deg-05split-fixed/crit_run4-lr=5e-05-critic_filters=24-generator_filters=48-generator_k_size=15/', compile=False)\n",
    "c_model.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize test signals so the critic can compare generated with real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalized_signals = test_signals * (np.expand_dims(1e19/test_conditions[:, 0], axis=-1) * (np.expand_dims(((test_conditions[:, 1]/units.deg - cherenkov_angle/units.deg))**4, axis=-1) + 1)/3)\n",
    "normalized_signals = test_signals * (np.expand_dims(1e19/test_conditions[:, 0], axis=-1) * (np.expand_dims(((test_conditions[:, 1]/units.deg - cherenkov_angle/units.deg))**4, axis=-1) + 1)/6)\n",
    "# normalized_signals = np.zeros_like(test_signals)\n",
    "# for i in range(test_signals.shape[0]):\n",
    "#    normalized_signals[i, :] = test_signals[i, :]*(1e19/test_conditions[i, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_logits = c_model.predict([pred_signals, test_conditions_norm])\n",
    "real_logits = c_model.predict([normalized_signals, test_conditions_norm])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter estimated wasserstein distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" d_cost = np.zeros((n_rows, ))\n",
    "for i in range(n_rows):\n",
    "    d_cost[i] = cWGANGP_model_def.critic_loss(real_sig=real_logits[i*10:i*10+10], fake_sig=fake_logits[i*10:i*10+10]) \"\"\"\n",
    "plt.scatter(range(np.abs(fake_logits-real_logits).size), np.abs(fake_logits-real_logits), s=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot signal with the lowest w-distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = fake_logits-real_logits\n",
    "min = np.abs(diff).argmin() #  min w-dist\n",
    "max = np.abs(diff).argmax() #  max w-dist\n",
    "\n",
    "max2 = np.argmax(diff[diff != np.amin(diff)]) #  second max w-dist\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8,5))\n",
    "ax.plot(x[400:560], test_signals[min, 400:560]/units.millivolt, label='real signal')\n",
    "ax.plot(x[400:560], pred_signals_scaled[min, 400:560]/units.millivolt, '--', label='pred signal')\n",
    "ax.xaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "ax.yaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "ax.legend(frameon=False)\n",
    "ax.set_xlabel('Time [ns]')\n",
    "ax.set_ylabel('Amplitude [mV/m]')\n",
    "#fig.savefig('thesis/Exjobb-rapport/figures/c_score_best.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the signal with the highest w-distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8,5))\n",
    "\n",
    "ax.plot(x[350:500], test_signals[max2, 350:500]/units.millivolt, label='real signal')\n",
    "ax.plot(x[350:500], pred_signals_scaled[max2, 350:500]/units.millivolt, '--', label='pred signal')\n",
    "\n",
    "ax.xaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "ax.yaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "ax.legend(frameon=False)\n",
    "ax.set_xlabel('Time [ns]')\n",
    "ax.set_ylabel('Amplitude [mV/m]')\n",
    "fig.savefig('thesis/Exjobb-rapport/figures/c_score_worst.pdf')\n",
    "\n",
    "print(f'max diff={diff[max2]}, real logit={real_logits[max2]}, fake logits={fake_logits[max2]}, given condition: {test_conditions[max2,0]:.3E}, {test_conditions[max2,1]/units.deg:.2f}')\n",
    "print(f'min diff: {diff[min]}, real logit={real_logits[min]}, fake logits={fake_logits[min]}, given condition: {test_conditions[min,0]:.3E}, {test_conditions[min,1]/units.deg:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See if there is a clear pattern in the w-distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.stack((diff.squeeze(), (test_conditions[:,1] - cherenkov_angle)/units.deg, np.log10(test_conditions[:,0])), axis=-1), columns=['w-dist', 'angle', 'log-E'])\n",
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute fluence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import integrate as quad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_energy = quad.simpson(np.power(test_signals, 2), x=x, axis=-1)\n",
    "gen_energy = quad.simpson(np.power(pred_signals_scaled, 2), x=x, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute error in peak to peak amplitude and fluence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_real_energy = np.zeros((real_energy.shape[0]//10, ))\n",
    "std_real_energy = np.zeros((real_energy.shape[0]//10, ))\n",
    "avg_peak2peak = np.zeros((real_energy.shape[0]//10, ))\n",
    "std_peak2peak = np.zeros((real_energy.shape[0]//10, ))\n",
    "for i in range(avg_real_energy.shape[0]):\n",
    "    avg_real_energy[i] = np.mean(real_energy[i*10:i*10+10], axis=0)\n",
    "    std_real_energy[i] = np.std(real_energy[i*10:i*10+10], axis=0)\n",
    "    max = np.max(test_signals[i*10:i*10+10], axis=-1)\n",
    "    min = np.min(test_signals[i*10:i*10+10], axis=-1)\n",
    "    avg_peak2peak[i] = np.mean(max-min)\n",
    "    std_peak2peak[i] = np.std(max-min)\n",
    "\n",
    "energy_err = np.zeros((pred_signals_scaled.shape[0], ))\n",
    "peak_err = np.zeros((pred_signals_scaled.shape[0], ))\n",
    "for i in range(pred_signals_scaled.shape[0]):\n",
    "    err = np.abs(gen_energy[i] - avg_real_energy[i//10])\n",
    "    if err > std_real_energy[i//10]:\n",
    "        err = err**2\n",
    "    else:\n",
    "        err = 0\n",
    "    energy_err[i] = err\n",
    "    \n",
    "    max = np.max(pred_signals_scaled[i])\n",
    "    min = np.min(pred_signals_scaled[i])\n",
    "    p_err = np.abs(avg_peak2peak[i//10] - (max - min))\n",
    "    if err > std_peak2peak[i//10]:\n",
    "        p_err = p_err**2\n",
    "    else:\n",
    "        p_err = 0\n",
    "    peak_err[i] = p_err\n",
    "\n",
    "\n",
    "plt.scatter(np.repeat(avg_peak2peak,10), peak_err/np.repeat(avg_peak2peak,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and plot losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = pd.read_pickle(f'GAN_losses/history_run4-lr=5e-05-critic_filters=24-generator_filters=48-generator_k_size=15.pkl')\n",
    "history.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moving average\n",
    "window = 16\n",
    "loss_length = history['g_loss'].shape[0]//window\n",
    "mean_g_loss = np.zeros((loss_length,))\n",
    "mean_d_loss = np.zeros((loss_length,))\n",
    "mean_d_cost = np.zeros((loss_length,))\n",
    "mean_gp = np.zeros((loss_length,))\n",
    "for i in range(loss_length):\n",
    "    mean_g_loss[i] = np.mean(history['g_loss'][i*window:i*window+window])\n",
    "    mean_d_loss[i] = np.mean(history['c_loss'][i*window:i*window+window])\n",
    "    mean_d_cost[i] = np.mean(history['c_cost'][i*window:i*window+window])\n",
    "    mean_gp[i//window] = np.mean(history['gp'][i*window:i*window+window])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geanerator loss\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8,5))\n",
    "x = np.linspace(1,100, 2000*4)\n",
    "ax.xaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "ax.yaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "plt.plot(x, mean_g_loss, label='generator loss', color=pal[0])\n",
    "#plt.legend(frameon=False)\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "#fig.savefig('thesis/Exjobb-rapport/figures/gan_g_loss_best.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# critic losses\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.plot([-5, 105], [0, 0], ':', color=pal[3], alpha=1)\n",
    "#ax.yaxis.grid(True)\n",
    "ax.set_xlim(-5, 105)\n",
    "ax.plot(x, mean_d_loss, label='total critic loss', color=pal[0])\n",
    "ax.plot(x, mean_gp*10, label='gradient penalty', color=pal[1])\n",
    "ax.plot(x, mean_d_cost, label='wasserstein loss', color=pal[2])\n",
    "ax.xaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "ax.yaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "ax.legend(frameon=False)\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "#fig.savefig('thesis/Exjobb-rapport/figures/gan_c_loss_best.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras.utils.plot_model(g_model, rankdir='LR', show_layer_names=False, show_shapes=False, dpi=300, to_file='g_model_example.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load results from random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = pd.read_pickle(f'GAN_losses/signal_gan_results_transconv-incept-m14-10deg-05split-fixed.pkl')\n",
    "peak_err = models['peak_err']\n",
    "p_max_run = np.argmax(peak_err)\n",
    "p_min_run = np.argmin(peak_err)\n",
    "energy_err = models['energy_err']\n",
    "e_max_run = np.argmax(energy_err)\n",
    "e_min_run = np.argmin(energy_err)\n",
    "w_dist = models['w_dist']\n",
    "w_max_run = np.argmax(w_dist)\n",
    "w_min_run = np.argmin(w_dist)\n",
    "print(p_max_run, e_max_run, w_max_run)\n",
    "print(p_min_run, e_min_run, w_min_run)\n",
    "models.sort_values('energy_err')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.iloc[13]['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a latex table of top five and bottom five models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = models.sort_values('energy_err', ascending=True)[:10]\n",
    "tmp['energy_err'] = (tmp['energy_err']*100).map(\"{:.2f}\".format) + '%'\n",
    "tmp['peak_err'] = (tmp['peak_err']*100).map(\"{:.2f}\".format) + '%'\n",
    "tmp['w_dist'] = (tmp['w_dist']).map(\"{:.3f}\".format)\n",
    "tmp['lr'] = (tmp['lr']).map(float)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tmp.to_latex(\n",
    "    index=False,\n",
    "    float_format='%.0E',\n",
    "    columns=['energy_err', 'peak_err', 'w_dist', 'lr', 'critic_filters', 'generator_filters', 'generator_k_size'],\n",
    "    header=['Energy error', 'p2p error', 'Wasserstein', 'learning rate', 'C filters', 'G filters', 'G kernel size']\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f00e6b041018f9c5003ba88af84c1401696fe75920157f0e0f441a09854937f6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('tf-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
